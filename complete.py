# SISTEMA NUVE v2.1 - AnÃ¡lise de ViolÃªncia em "nome da pasta" MÃ©dicos
# CÃ³digo completo para execuÃ§Ã£o no Google Colab

#  INSTALAÃ‡ÃƒO DE DEPENDÃŠNCIAS
print("ðŸ“¦ Instalando dependÃªncias necessÃ¡rias...")

!pip install pdfplumber pdf2image pytesseract pandas gspread google-auth PyMuPDF openpyxl -q
!sudo apt update > /dev/null 2>&1
!sudo apt install tesseract-ocr libtesseract-dev poppler-utils -y > /dev/null 2>&1

print("âœ… DependÃªncias instaladas com sucesso!")

# MONTAGEM DO GOOGLE DRIVE 
print("\nðŸ“ Montando Google Drive...")

from google.colab import drive
drive.mount('/content/drive')

print("âœ… Google Drive montado com sucesso!")

# CONFIGURAÃ‡ÃƒO
FOLDER_PATH = '/content/drive/MyDrive/"nome da pasta"_Nuve'
RESULTS_PATH = '/content/results_nuve'

print(f"\nðŸŽ¯ Pasta configurada: {FOLDER_PATH}")

# VerificaÃ§Ã£o da pasta
import os
from pathlib import Path

if os.path.exists(FOLDER_PATH):
    pdf_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith('.pdf')]
    print(f"âœ… Pasta encontrada! {len(pdf_files)} PDFs detectados:")
    for i, pdf in enumerate(pdf_files[:5]):
        print(f"  {i+1}. {pdf}")
    if len(pdf_files) > 5:
        print(f"  ... e mais {len(pdf_files)-5} arquivos")
else:
    print(f"âŒ ATENÃ‡ÃƒO: Pasta nÃ£o encontrada!")
    print("Certifique-se de que a pasta '"nome da pasta"_Nuve' existe no seu Google Drive")

# IMPORTAÃ‡Ã•ES
print("\nðŸ”§ Importando bibliotecas...")

import re
import json
import hashlib
import logging
import tempfile
import zipfile
import csv
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple, Set
from datetime import datetime
from collections import defaultdict, Counter
from enum import Enum
import pytz
from pathlib import Path

# Imports para processamento de PDF
try:
    import pdfplumber
    HAS_PDFPLUMBER = True
except ImportError:
    HAS_PDFPLUMBER = False

try:
    import fitz  # PyMuPDF
    HAS_FITZ = True
except ImportError:
    HAS_FITZ = False

try:
    import pytesseract
    from pdf2image import convert_from_path
    from PIL import Image
    HAS_OCR = True
except ImportError:
    HAS_OCR = False

print("âœ… Bibliotecas importadas com sucesso!")

# CONFIGURAÃ‡Ã•ES E ENUMS 

@dataclass
class ProcessingConfig:
    ocr_threshold: int = 100
    max_file_size_mb: int = 50
    context_window_chars: int = 150
    min_text_quality_chars: int = 30
    anonymize_identifiers: bool = True
    secure_temp_processing: bool = True
    log_sensitive_data: bool = False
    batch_size: int = 10
    enable_parallel_processing: bool = False
    cache_compiled_patterns: bool = True
    output_formats: List[str] = field(default_factory=lambda: ['csv', 'json'])
    include_context_phrases: bool = True
    max_phrases_per_document: int = 25
    enable_pattern_analysis: bool = True

class ProcessingStatus(Enum):
    SUCCESS = "sucesso"
    PDF_CORRUPTED = "pdf_corrompido"
    OCR_FAILED = "ocr_falhou"
    INSUFFICIENT_TEXT = "texto_insuficiente"
    PROCESSING_ERROR = "erro_processamento"
    SECURITY_ERROR = "erro_seguranca"

class QualityLevel(Enum):
    EXCELLENT = "excelente"
    GOOD = "boa"
    FAIR = "regular"
    POOR = "ruim"

class SeverityLevel(Enum):
    CRITICAL = "CRÃTICO"
    HIGH = "ALTO"
    MODERATE = "MODERADO"
    LOW = "BAIXO"
    MINIMAL = "MÃNIMO"
    NONE = "SEM INDICAÃ‡ÃƒO"

class DocumentType(Enum):
    EVOLUCAO_MEDICA = "EvoluÃ§Ã£o MÃ©dica"
    ANOTACOES_ENFERMAGEM = "AnotaÃ§Ãµes da Enfermagem"
    MULTIPROFISSIONAL = "Multiprofissional"
    OUTROS = "Outros"

# MODELOS DE DADOS

@dataclass
class PatientIdentifier:
    patient_id: str
    document_hash: str
    filename: str
    extracted_ids: Dict[str, str] = field(default_factory=dict)
    rghc: Optional[str] = None
    codigo_paciente: Optional[str] = None
    cpf: Optional[str] = None
    data_nascimento: Optional[str] = None
    nome_paciente: Optional[str] = None

@dataclass
class PageInfo:
    page_number: int
    page_text: str
    page_metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class DocumentMetadata:
    document_date: Optional[str] = None
    document_type: DocumentType = DocumentType.OUTROS
    creation_date: Optional[str] = None
    author: Optional[str] = None
    service: Optional[str] = None

@dataclass
class TextContent:
    text: str
    page_count: int
    extraction_method: str
    quality_level: QualityLevel
    char_count: int
    word_count: int
    metadata: Dict[str, Any] = field(default_factory=dict)
    pages_info: List[PageInfo] = field(default_factory=list)
    document_metadata: DocumentMetadata = field(default_factory=DocumentMetadata)

@dataclass
class ViolenceDetection:
    term: str
    category: str
    base_weight: float
    adjusted_weight: float
    context_phrase: str
    position_start: int
    position_end: int
    confidence_score: float = 1.0
    intensity_multiplier: float = 1.0
    found_date: Optional[str] = None
    full_sentence: str = ""
    page_number: int = 0
    document_date: Optional[str] = None

@dataclass
class ViolencePatterns:
    chronic_violence: bool = False
    escalation_pattern: bool = False
    weapons_involved: bool = False
    children_present: bool = False
    pregnancy_violence: bool = False
    sexual_violence: bool = False
    death_threats: bool = False
    multiple_injuries: bool = False
    psychological_control: bool = False
    economic_abuse: bool = False
    pattern_severity_score: float = 0.0

@dataclass
class AnalysisResult:
    patient_id: PatientIdentifier
    text_content: TextContent
    total_score: float
    base_score: float
    contextual_bonus: float
    severity_level: str
    detections: List[ViolenceDetection]
    violence_patterns: ViolencePatterns
    category_scores: Dict[str, float]
    category_counts: Dict[str, int]
    context_phrases: List[str]
    processing_time_ms: int
    status: ProcessingStatus
    error_message: Optional[str] = None

# BASE LEXICAL EXPANDIDA

class ExpandedViolenceLexicon:
    """Base lexical expandida com 1500+ termos para detecÃ§Ã£o de violÃªncia mÃ©dica"""

    def __init__(self):
        self.categories = self._load_expanded_violence_lexicon()
        self.compiled_patterns = {}
        self.negation_patterns = self._compile_negation_patterns()
        self.contextual_patterns = self._compile_contextual_patterns()
        self._compile_all_patterns()

    def _load_expanded_violence_lexicon(self) -> Dict[str, Dict[str, Any]]:
        """Carrega base lexical expandida com categorias especializadas"""
        return {
            "medical_formal": {
                "weight": 2.8,
                "terms": [
                    "trauma contundente", "trauma por forÃ§a contusa", "lesÃ£o contundente",
                    "trauma cranioencefÃ¡lico", "TCE", "traumatismo craniano", "trauma facial",
                    "trauma cervical", "trauma torÃ¡cico", "trauma abdominal", "politraumatismo",
                    "hematoma subdural", "hematoma epidural", "hematoma intracraniano",
                    "hematoma retroauricular", "hematoma periorbitÃ¡rio", "hematoma occipital",
                    "equimose periorbital", "hematoma periorbital", "olho roxo", "olho negro",
                    "equimoses mÃºltiplas", "equimoses em diferentes estÃ¡gios", "equimoses bilaterais",
                    "laceraÃ§Ã£o cutÃ¢nea", "laceraÃ§Ã£o facial", "laceraÃ§Ã£o profunda",
                    "laceraÃ§Ã£o do couro cabeludo", "laceraÃ§Ã£o labial", "laceraÃ§Ã£o genital",
                    "ferimento corto-contuso", "ferimento inciso", "ferimento perfurante",
                    "ferimento por arma de fogo", "ferimento por arma branca", "lesÃ£o por projÃ©til",
                    "fratura de mandÃ­bula", "fratura maxilar", "fratura facial", "fratura nasal",
                    "fratura de Ã³rbita", "fratura zigomÃ¡tica", "fratura do arco zigomÃ¡tico",
                    "fratura de costela", "fraturas mÃºltiplas", "fratura espiral",
                    "queimadura intencional", "queimadura por cigarro", "queimadura circunscrita",
                    "queimadura por lÃ­quido quente", "queimadura por ferro", "queimadura em luva",
                    "escoriaÃ§Ãµes mÃºltiplas", "escoriaÃ§Ãµes lineares", "escoriaÃ§Ãµes ungueais",
                    "marcas de mordida humana", "marcas de dedos", "marcas de mÃ£o",
                    "marcas de corda", "marcas de estrangulamento", "marcas de amarraÃ§Ã£o",
                    "petÃ©quias no pescoÃ§o", "equimoses cervicais", "sulco de enforcamento",
                    "lesÃµes de defesa", "ferimentos defensivos", "trauma nÃ£o acidental",
                    "violÃªncia sexual", "estupro", "abuso sexual", "trauma genital",
                    "laceraÃ§Ã£o vaginal", "laceraÃ§Ã£o anal", "lesÃ£o himenal", "hematoma genital",
                    "negligÃªncia grave", "desnutriÃ§Ã£o proteico-calÃ³rica", "abandono de incapaz",
                    "desidrataÃ§Ã£o severa", "mÃ¡ higiene corporal", "lesÃµes por decÃºbito",
                    "transtorno de estresse pÃ³s-traumÃ¡tico", "TEPT", "depressÃ£o reativa",
                    "ansiedade pÃ³s-traumÃ¡tica", "dissociaÃ§Ã£o", "flashbacks",
                    "ideaÃ§Ã£o suicida", "tentativa de suicÃ­dio", "automutilaÃ§Ã£o", "autoextermÃ­nio",
                    "comportamento autodestrutivo", "tentativa de autolesÃ£o",
                    "sÃ­ndrome do bebÃª sacudido", "trauma craniano nÃ£o acidental",
                    "hemorragia retiniana", "hematoma subdural em crianÃ§a"
                ]
            },
            "legal_police": {
                "weight": 2.5,
                "terms": [
                    "agressÃ£o fÃ­sica", "agressÃ£o corporal", "violÃªncia fÃ­sica",
                    "lesÃ£o corporal", "lesÃ£o corporal leve", "lesÃ£o corporal grave",
                    "lesÃ£o corporal gravÃ­ssima", "vias de fato", "violÃªncia domÃ©stica",
                    "ameaÃ§a", "ameaÃ§a de morte", "intimidaÃ§Ã£o", "ameaÃ§a grave",
                    "ameaÃ§a com arma", "ameaÃ§a de espancamento", "intimidaÃ§Ã£o psicolÃ³gica",
                    "chantagem", "extorsÃ£o", "coaÃ§Ã£o", "constrangimento ilegal",
                    "cÃ¡rcere privado", "sequestro", "sequestro relÃ¢mpago",
                    "privaÃ§Ã£o de liberdade", "confinamento forÃ§ado", "aprisionamento",
                    "estupro", "estupro de vulnerÃ¡vel", "atentado violento ao pudor",
                    "assÃ©dio sexual", "abuso sexual", "exploraÃ§Ã£o sexual",
                    "violÃªncia sexual", "estupro conjugal", "sexo forÃ§ado",
                    "homicÃ­dio", "tentativa de homicÃ­dio", "feminicÃ­dio",
                    "tentativa de feminicÃ­dio", "latrocÃ­nio", "assassinato",
                    "arma branca", "arma de fogo", "objeto contundente",
                    "faca", "revÃ³lver", "pistola", "martelo",
                    "bastÃ£o", "cassetete", "pedra", "tijolo",
                    "espancamento", "surra", "paulada", "facada", "tiro",
                    "enforcamento", "estrangulamento", "sufocamento", "asfixia",
                    "boletim de ocorrÃªncia", "B.O.", "inquÃ©rito policial",
                    "termo circunstanciado", "flagrante delito", "prisÃ£o em flagrante",
                    "medida protetiva de urgÃªncia", "ordem de proteÃ§Ã£o",
                    "exame de corpo de delito", "laudo pericial", "perÃ­cia criminal"
                ]
            },
            "maria_penha_domestic": {
                "weight": 2.3,
                "terms": [
                    "violÃªncia domÃ©stica", "violÃªncia intrafamiliar", "violÃªncia conjugal",
                    "violÃªncia de gÃªnero", "violÃªncia contra mulher", "maus-tratos domÃ©sticos",
                    "violÃªncia no lar", "agressÃ£o domÃ©stica", "abuso domÃ©stico",
                    "feminicÃ­dio", "tentativa de feminicÃ­dio", "crime passional",
                    "ciclo da violÃªncia", "ciclo de abuso", "escalada da violÃªncia",
                    "violÃªncia repetitiva", "padrÃ£o de agressÃ£o", "histÃ³rico de violÃªncia",
                    "relacionamento abusivo", "namoro violento", "parceiro abusivo",
                    "companheiro violento", "marido agressor", "ex-parceiro violento",
                    "violÃªncia fÃ­sica domÃ©stica", "violÃªncia psicolÃ³gica", "violÃªncia moral",
                    "violÃªncia sexual conjugal", "violÃªncia patrimonial", "violÃªncia econÃ´mica",
                    "controle coercitivo", "dominaÃ§Ã£o psicolÃ³gica", "ciÃºmes patolÃ³gicos",
                    "possessividade excessiva", "controle obsessivo", "comportamento controlador",
                    "isolamento social forÃ§ado", "proibiÃ§Ã£o de trabalhar", "proibiÃ§Ã£o de sair",
                    "proibiÃ§Ã£o de estudar", "afastamento da famÃ­lia", "isolamento de amigos",
                    "monitoramento digital", "controle de celular", "cyberstalking",
                    "violÃªncia virtual", "stalking digital", "perseguiÃ§Ã£o online",
                    "humilhaÃ§Ã£o constante", "gaslighting", "chantagem emocional",
                    "manipulaÃ§Ã£o psicolÃ³gica", "terrorismo psicolÃ³gico", "tortura psicolÃ³gica",
                    "destruiÃ§Ã£o de objetos pessoais", "controle financeiro absoluto",
                    "privaÃ§Ã£o de recursos", "destruiÃ§Ã£o de documentos", "delegacia da mulher",
                    "casa abrigo", "medidas protetivas", "centro de referÃªncia"
                ]
            },
            "healthcare_nursing": {
                "weight": 2.0,
                "terms": [
                    "paciente relata violÃªncia", "usuÃ¡rio informa agressÃ£o", "refere maus-tratos",
                    "histÃ³ria de violÃªncia", "episÃ³dios de violÃªncia", "relato de agressÃ£o",
                    "menciona espancamento", "conta sobre agressÃ£o", "narra violÃªncia",
                    "histÃ³ria pregressa de violÃªncia", "episÃ³dios anteriores de violÃªncia",
                    "antecedentes de maus-tratos", "histÃ³rico de agressÃµes",
                    "violÃªncia recorrente", "agressÃµes repetidas", "maus-tratos crÃ´nicos",
                    "sinais evidentes de violÃªncia", "indÃ­cios de maus-tratos",
                    "suspeita de violÃªncia domÃ©stica", "lesÃµes compatÃ­veis com agressÃ£o",
                    "ferimentos sugestivos", "padrÃ£o de lesÃµes", "lesÃµes nÃ£o acidentais",
                    "hematomas mÃºltiplos", "equimoses generalizadas", "roxos pelo corpo",
                    "marcas visÃ­veis", "ferimentos em cicatrizaÃ§Ã£o", "lesÃµes recentes",
                    "queimaduras circunscritas", "marca de cigarro", "queimadura suspeita",
                    "escoriaÃ§Ãµes lineares", "arranhÃµes defensivos", "marcas de unhas",
                    "dinÃ¢mica familiar conturbada", "relacionamento conjugal conflituoso",
                    "ambiente familiar violento", "tensÃ£o familiar evidente",
                    "filhos presenciam violÃªncia", "crianÃ§as traumatizadas",
                    "menores expostos Ã  violÃªncia", "impacto psicolÃ³gico nas crianÃ§as",
                    "comportamento de submissÃ£o", "evita contato visual", "hipervigilÃ¢ncia",
                    "medo excessivo", "ansiedade extrema", "comportamento evasivo",
                    "tremores generalizados", "sudorese profusa", "taquicardia",
                    "notificaÃ§Ã£o compulsÃ³ria", "ficha de notificaÃ§Ã£o de violÃªncia",
                    "comunicaÃ§Ã£o ao conselho tutelar", "relatÃ³rio de suspeita"
                ]
            },
            "colloquial_popular": {
                "weight": 1.8,
                "terms": [
                    "surra", "porrada", "pancada", "sova", "cacetada", "paulada",
                    "bordoada", "tapÃ£o", "sopapo", "bicuda", "coice", "pescoÃ§Ã£o",
                    "soco", "murro", "tapa", "bofetada", "cascudo", "chute", "pontapÃ©",
                    "joelhada", "cabeÃ§ada", "cotovelada", "pisÃ£o", "empurrÃ£o", "beliscÃ£o",
                    "bateu na mulher", "agrediu a esposa", "espancou a companheira",
                    "deu uma surra", "quebrou na porrada", "meteu a mÃ£o",
                    "me bateu", "apanhei dele", "levei surra", "me deu porrada",
                    "me agrediu", "me espancou", "bateu em mim", "me machucou",
                    "ameaÃ§ou me matar", "disse que me mata", "prometeu me acabar",
                    "falou que ia me quebrar", "ameaÃ§ou me dar uma surra",
                    "muito ciumento", "nÃ£o deixa sair", "controla tudo", "mexe no celular",
                    "nÃ£o deixa trabalhar", "vigia sempre", "segue para todo lado",
                    "me forÃ§ou", "me obrigou", "nÃ£o aceitou nÃ£o", "forÃ§ou a barra",
                    "briga de casal", "confusÃ£o em casa", "quebra-pau em casa",
                    "barraco em casa", "discussÃ£o feia", "briga violenta",
                    "bebe e fica violento", "viciado agressivo", "noiado violento",
                    "tacou objeto", "jogou coisa", "atirou na parede",
                    "ficou todo roxo", "marcou o rosto", "deixou marca"
                ]
            },
            "orthographic_variations": {
                "weight": 1.5,
                "terms": [
                    "agressÃ£o", "agreÃ§Ã£o", "agressao", "agresÃ£o", "agrediu", "agridiu",
                    "agredindo", "agridindo", "agressor", "agresor", "agressivo", "agresivo",
                    "violÃªncia", "violencia", "violensia", "violensa", "violento", "violÃªnto",
                    "espancamento", "spancamento", "espancou", "espankou", "espancada",
                    "machucou", "machukou", "machucu", "machucado", "machucada",
                    "bateu", "batÃªu", "batu", "batendo", "bateno", "bater", "batÃª",
                    "ameaÃ§ou", "ameaÃ§Ã´", "ameaÃ§o", "ameaÃ§ando", "ameaÃ§ano", "ameaÃ§a", "ameasa",
                    "judiou", "judiÃ´", "judiar", "judiÃ¡", "maltratou", "maltratÃ³"
                ]
            },
            "psychological_abuse": {
                "weight": 1.9,
                "terms": [
                    "manipulaÃ§Ã£o psicolÃ³gica", "chantagem emocional", "gaslighting",
                    "lavagem cerebral", "distorÃ§Ã£o da realidade", "confusÃ£o mental induzida",
                    "humilhaÃ§Ã£o constante", "desmoralizaÃ§Ã£o", "diminuiÃ§Ã£o sistemÃ¡tica",
                    "isolamento social", "afastamento forÃ§ado", "separaÃ§Ã£o de familiares",
                    "controle mental", "dominaÃ§Ã£o psicolÃ³gica", "subjugaÃ§Ã£o emocional"
                ]
            },
            "child_specific": {
                "weight": 2.7,
                "terms": [
                    "maus-tratos infantis", "abuso infantil", "negligÃªncia infantil",
                    "violÃªncia contra crianÃ§a", "agressÃ£o a menor", "maltrato infantil",
                    "sÃ­ndrome do bebÃª sacudido", "trauma craniano nÃ£o acidental em crianÃ§a",
                    "lesÃµes nÃ£o acidentais em menor", "negligÃªncia de cuidados bÃ¡sicos",
                    "privaÃ§Ã£o de alimentos", "falta de higiene", "abandono de incapaz"
                ]
            }
        }

    def _compile_negation_patterns(self) -> List[re.Pattern]:
        """Compila padrÃµes de negaÃ§Ã£o expandidos"""
        negation_terms = [
            "nÃ£o", "nao", "jamais", "nunca", "nega", "negou", "descarta",
            "afasta", "exclui", "ausente", "sem", "inexistente", "improvÃ¡vel",
            "sem evidÃªncias", "sem indÃ­cios", "sem sinais", "descartado"
        ]

        patterns = []
        for term in negation_terms:
            pattern = re.compile(
                rf'\b{re.escape(term)}\b[\s\w]{{0,80}}\b(?:viol|agred|espanc|machuc|bat|surr|ameaÃ§|mal.?trat)\w*',
                re.IGNORECASE
            )
            patterns.append(pattern)

        return patterns

    def _compile_contextual_patterns(self) -> Dict[str, List[re.Pattern]]:
        """Compila padrÃµes contextuais expandidos"""
        return {
            "intensifying_contexts": [
                re.compile(r'\b(sempre|todo\s*dia|constantemente|frequentemente|diariamente|rotineiramente)\b.{0,50}\b(agred|bat|violent|maltrat)\w*', re.IGNORECASE),
                re.compile(r'\b(na\s*frente|presenÃ§a|vista)\b.{0,30}\b(crianÃ§as?|filhos?|menores?)\b.{0,50}\b(agred|bat|violent)\w*', re.IGNORECASE),
                re.compile(r'\b(grÃ¡vida|gestante|gestaÃ§Ã£o)\b.{0,50}\b(agred|bat|chut|violent|espanc)\w*', re.IGNORECASE),
                re.compile(r'\b(com|usando|ameaÃ§ou\s*com|empunhando)\b.{0,30}\b(faca|revÃ³lver|pistola|arma|martelo)\b', re.IGNORECASE),
            ],
            "medical_severity": [
                re.compile(r'\b(fratura|sangramento|hemorragia|trauma)\b.{0,30}\b(agred|bat|violent)\w*', re.IGNORECASE),
                re.compile(r'\b(cirurgia|sutura|pontos)\b.{0,50}\b(agred|bat|violent)\w*', re.IGNORECASE),
            ]
        }

    def _compile_all_patterns(self):
        """Compila todos os padrÃµes regex"""
        for category, data in self.categories.items():
            terms_escaped = [re.escape(term) for term in data['terms']]
            combined_pattern = '|'.join(terms_escaped)
            full_pattern = rf'(.{{0,150}})({combined_pattern})(.{{0,150}})'

            self.compiled_patterns[category] = {
                'pattern': re.compile(full_pattern, re.IGNORECASE | re.DOTALL),
                'weight': data['weight'],
                'terms_count': len(data['terms'])
            }

    def detect_negation_context(self, text: str, match_start: int, match_end: int) -> bool:
        """Detecta contexto de negaÃ§Ã£o"""
        context_start = max(0, match_start - 150)
        before_context = text[context_start:match_end]

        for negation_pattern in self.negation_patterns:
            if negation_pattern.search(before_context):
                return True
        return False

    def analyze_contextual_intensity(self, text: str, detection: ViolenceDetection) -> float:
        """Analisa intensidade contextual expandida"""
        intensity_multiplier = 1.0

        start = max(0, detection.position_start - 200)
        end = min(len(text), detection.position_end + 200)
        context = text[start:end].lower()

        # Verificar contextos intensificadores
        for pattern in self.contextual_patterns['intensifying_contexts']:
            if pattern.search(context):
                intensity_multiplier += 0.5

        # Verificar severidade mÃ©dica
        for pattern in self.contextual_patterns['medical_severity']:
            if pattern.search(context):
                intensity_multiplier += 0.7

        return max(0.1, min(5.0, intensity_multiplier))

    def detect_violence_patterns(self, text: str) -> ViolencePatterns:
        """Detecta padrÃµes especÃ­ficos de violÃªncia expandidos"""
        text_lower = text.lower()
        patterns = ViolencePatterns()

        # ViolÃªncia crÃ´nica
        chronic_indicators = ['sempre', 'todo dia', 'constantemente', 'anos', 'rotina', 'frequentemente']
        if any(indicator in text_lower for indicator in chronic_indicators):
            patterns.chronic_violence = True
            patterns.pattern_severity_score += 1.2

        # Armas
        weapons = ['faca', 'revolver', 'pistola', 'arma', 'martelo']
        if any(weapon in text_lower for weapon in weapons):
            patterns.weapons_involved = True
            patterns.pattern_severity_score += 1.8

        # CrianÃ§as presentes
        children_contexts = ['na frente das crianÃ§as', 'crianÃ§a viu', 'filho assistiu']
        if any(context in text_lower for context in children_contexts):
            patterns.children_present = True
            patterns.pattern_severity_score += 1.5

        # ViolÃªncia na gravidez
        pregnancy_terms = ['grÃ¡vida', 'gestante', 'chutou barriga']
        if any(term in text_lower for term in pregnancy_terms):
            patterns.pregnancy_violence = True
            patterns.pattern_severity_score += 2.2

        # ViolÃªncia sexual
        sexual_terms = ['estupro', 'abuso sexual', 'forÃ§ou', 'obrigou']
        if any(term in text_lower for term in sexual_terms):
            patterns.sexual_violence = True
            patterns.pattern_severity_score += 2.5

        # AmeaÃ§as de morte
        death_threats = ['vou te matar', 'vai morrer', 'ameaÃ§ou de morte']
        if any(threat in text_lower for threat in death_threats):
            patterns.death_threats = True
            patterns.pattern_severity_score += 2.0

        return patterns

# EXTRATOR DE TEXTO

class EnhancedTextExtractor:
    """Extrator de texto incrementado com informaÃ§Ãµes de pÃ¡gina e metadados"""

    def __init__(self, config: ProcessingConfig):
        self.config = config
        self.logger = logging.getLogger("EnhancedTextExtractor")
        self.document_classifier = DocumentClassifier()
        self.metadata_extractor = DocumentMetadataExtractor()

    def extract_from_pdf(self, pdf_path: Path) -> TextContent:
        """Extrai texto com informaÃ§Ãµes de pÃ¡gina e metadados"""

        # Validar arquivo
        self._validate_input_file(pdf_path)

        # Tentar mÃ©todos em ordem de preferÃªncia
        extraction_methods = []

        if HAS_PDFPLUMBER:
            extraction_methods.append(("pdfplumber", self._extract_with_pdfplumber))
        if HAS_FITZ:
            extraction_methods.append(("fitz", self._extract_with_fitz))
        if HAS_OCR:
            extraction_methods.append(("ocr", self._extract_with_ocr))

        if not extraction_methods:
            raise Exception("Nenhuma biblioteca de PDF disponÃ­vel")

        last_error = None

        for method_name, extract_method in extraction_methods:
            try:
                print(f"  Tentando {method_name}...")
                text, metadata, pages_info = extract_method(pdf_path)

                if self._is_sufficient_text(text):
                    quality = self._assess_text_quality(text)
                    print(f"  âœ“ Sucesso com {method_name}")

                    # Extrair metadados do documento
                    doc_metadata = self.metadata_extractor.extract_metadata(text, pages_info)

                    return TextContent(
                        text=self._clean_text(text),
                        page_count=metadata.get('page_count', 0),
                        extraction_method=method_name,
                        quality_level=quality,
                        char_count=len(text),
                        word_count=len(text.split()),
                        metadata=metadata,
                        pages_info=pages_info,
                        document_metadata=doc_metadata
                    )
                else:
                    print(f"  âš  Texto insuficiente com {method_name}")
            except Exception as e:
                last_error = e
                print(f"  âœ— {method_name} falhou: {e}")
                continue

        raise Exception(f"Todos os mÃ©todos falharam para {pdf_path.name}. Ãšltimo erro: {last_error}")

    def _validate_input_file(self, file_path: Path):
        """Valida arquivo de entrada"""
        if not file_path.exists():
            raise FileNotFoundError(f"Arquivo nÃ£o encontrado: {file_path}")

        file_size_mb = file_path.stat().st_size / (1024 * 1024)
        if file_size_mb > self.config.max_file_size_mb:
            raise Exception(f"Arquivo muito grande: {file_size_mb:.2f}MB")

        if file_path.suffix.lower() != '.pdf':
            raise Exception(f"Tipo de arquivo nÃ£o suportado: {file_path.suffix}")

    def _extract_with_pdfplumber(self, pdf_path: Path) -> Tuple[str, Dict, List[PageInfo]]:
        """ExtraÃ§Ã£o com pdfplumber - INCREMENTADA"""
        text = ""
        metadata = {"method": "pdfplumber", "pages_processed": []}
        pages_info = []

        with pdfplumber.open(pdf_path) as pdf:
            metadata['page_count'] = len(pdf.pages)

            for i, page in enumerate(pdf.pages):
                try:
                    page_text = page.extract_text()
                    if page_text and len(page_text.strip()) > 10:
                        text += f"\n--- PÃGINA {i+1} ---\n{page_text}\n"
                        metadata['pages_processed'].append(i+1)

                        # Criar informaÃ§Ãµes da pÃ¡gina
                        page_info = PageInfo(
                            page_number=i+1,
                            page_text=page_text,
                            page_metadata={
                                'width': page.width,
                                'height': page.height,
                                'rotation': getattr(page, 'rotation', 0)
                            }
                        )
                        pages_info.append(page_info)
                except Exception:
                    continue

        return text, metadata, pages_info

    def _extract_with_fitz(self, pdf_path: Path) -> Tuple[str, Dict, List[PageInfo]]:
        """ExtraÃ§Ã£o com PyMuPDF - INCREMENTADA"""
        text = ""
        metadata = {"method": "fitz", "pages_processed": []}
        pages_info = []

        doc = fitz.open(pdf_path)
        metadata['page_count'] = len(doc)

        for page_num in range(len(doc)):
            try:
                page = doc.load_page(page_num)
                page_text = page.get_text()
                if page_text and len(page_text.strip()) > 10:
                    text += f"\n--- PÃGINA {page_num+1} ---\n{page_text}\n"
                    metadata['pages_processed'].append(page_num+1)

                    # Criar informaÃ§Ãµes da pÃ¡gina
                    page_info = PageInfo(
                        page_number=page_num+1,
                        page_text=page_text,
                        page_metadata={
                            'rect': page.rect,
                            'rotation': page.rotation
                        }
                    )
                    pages_info.append(page_info)
            except Exception:
                continue

        doc.close()
        return text, metadata, pages_info

    def _extract_with_ocr(self, pdf_path: Path) -> Tuple[str, Dict, List[PageInfo]]:
        """ExtraÃ§Ã£o com OCR - INCREMENTADA"""
        text = ""
        metadata = {"method": "ocr", "pages_processed": []}
        pages_info = []

        try:
            pages = convert_from_path(pdf_path, dpi=300, first_page=1, last_page=5)
            metadata['page_count'] = len(pages)

            for i, page_image in enumerate(pages):
                try:
                    page_text = pytesseract.image_to_string(page_image, lang='por')

                    if page_text and len(page_text.strip()) > 20:
                        text += f"\n--- PÃGINA {i+1} (OCR) ---\n{page_text}\n"
                        metadata['pages_processed'].append(i+1)

                        # Criar informaÃ§Ãµes da pÃ¡gina
                        page_info = PageInfo(
                            page_number=i+1,
                            page_text=page_text,
                            page_metadata={
                                'ocr_method': 'pytesseract',
                                'image_size': page_image.size
                            }
                        )
                        pages_info.append(page_info)
                except Exception:
                    continue
        except Exception as e:
            raise Exception(f"Erro OCR: {e}")

        return text, metadata, pages_info

    def _is_sufficient_text(self, text: str) -> bool:
        """Verifica se o texto Ã© suficiente"""
        if not text:
            return False
       
