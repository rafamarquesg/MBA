# SISTEMA NUVE v2.1 - An√°lise de Viol√™ncia em "nome da pasta" M√©dicos
# C√≥digo completo para execu√ß√£o no Google Colab

#  INSTALA√á√ÉO DE DEPEND√äNCIAS
print("üì¶ Instalando depend√™ncias necess√°rias...")

!pip install pdfplumber pdf2image pytesseract pandas gspread google-auth PyMuPDF openpyxl -q
!sudo apt update > /dev/null 2>&1
!sudo apt install tesseract-ocr libtesseract-dev poppler-utils -y > /dev/null 2>&1

print("‚úÖ Depend√™ncias instaladas com sucesso!")

# MONTAGEM DO GOOGLE DRIVE 
print("\nüìÅ Montando Google Drive...")

from google.colab import drive
drive.mount('/content/drive')

print("‚úÖ Google Drive montado com sucesso!")

# CONFIGURA√á√ÉO
FOLDER_PATH = '/content/drive/MyDrive/"nome da pasta"_Nuve'
RESULTS_PATH = '/content/results_nuve'

print(f"\nüéØ Pasta configurada: {FOLDER_PATH}")

# Verifica√ß√£o da pasta
import os
from pathlib import Path

if os.path.exists(FOLDER_PATH):
    pdf_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith('.pdf')]
    print(f"‚úÖ Pasta encontrada! {len(pdf_files)} PDFs detectados:")
    for i, pdf in enumerate(pdf_files[:5]):
        print(f"  {i+1}. {pdf}")
    if len(pdf_files) > 5:
        print(f"  ... e mais {len(pdf_files)-5} arquivos")
else:
    print(f"‚ùå ATEN√á√ÉO: Pasta n√£o encontrada!")
    print("Certifique-se de que a pasta '"nome da pasta"_Nuve' existe no seu Google Drive")

# IMPORTA√á√ïES
print("\nüîß Importando bibliotecas...")

import re
import json
import hashlib
import logging
import tempfile
import zipfile
import csv
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple, Set
from datetime import datetime
from collections import defaultdict, Counter
from enum import Enum
import pytz
from pathlib import Path

# Imports para processamento de PDF
try:
    import pdfplumber
    HAS_PDFPLUMBER = True
except ImportError:
    HAS_PDFPLUMBER = False

try:
    import fitz  # PyMuPDF
    HAS_FITZ = True
except ImportError:
    HAS_FITZ = False

try:
    import pytesseract
    from pdf2image import convert_from_path
    from PIL import Image
    HAS_OCR = True
except ImportError:
    HAS_OCR = False

print("‚úÖ Bibliotecas importadas com sucesso!")

# CONFIGURA√á√ïES E ENUMS 

@dataclass
class ProcessingConfig:
    ocr_threshold: int = 100
    max_file_size_mb: int = 50
    context_window_chars: int = 150
    min_text_quality_chars: int = 30
    anonymize_identifiers: bool = True
    secure_temp_processing: bool = True
    log_sensitive_data: bool = False
    batch_size: int = 10
    enable_parallel_processing: bool = False
    cache_compiled_patterns: bool = True
    output_formats: List[str] = field(default_factory=lambda: ['csv', 'json'])
    include_context_phrases: bool = True
    max_phrases_per_document: int = 25
    enable_pattern_analysis: bool = True

class ProcessingStatus(Enum):
    SUCCESS = "sucesso"
    PDF_CORRUPTED = "pdf_corrompido"
    OCR_FAILED = "ocr_falhou"
    INSUFFICIENT_TEXT = "texto_insuficiente"
    PROCESSING_ERROR = "erro_processamento"
    SECURITY_ERROR = "erro_seguranca"

class QualityLevel(Enum):
    EXCELLENT = "excelente"
    GOOD = "boa"
    FAIR = "regular"
    POOR = "ruim"

class SeverityLevel(Enum):
    CRITICAL = "CR√çTICO"
    HIGH = "ALTO"
    MODERATE = "MODERADO"
    LOW = "BAIXO"
    MINIMAL = "M√çNIMO"
    NONE = "SEM INDICA√á√ÉO"

class DocumentType(Enum):
    EVOLUCAO_MEDICA = "Evolu√ß√£o M√©dica"
    ANOTACOES_ENFERMAGEM = "Anota√ß√µes da Enfermagem"
    MULTIPROFISSIONAL = "Multiprofissional"
    OUTROS = "Outros"

# MODELOS DE DADOS

@dataclass
class PatientIdentifier:
    patient_id: str
    document_hash: str
    filename: str
    extracted_ids: Dict[str, str] = field(default_factory=dict)
    rghc: Optional[str] = None
    codigo_paciente: Optional[str] = None
    cpf: Optional[str] = None
    data_nascimento: Optional[str] = None
    nome_paciente: Optional[str] = None

@dataclass
class PageInfo:
    page_number: int
    page_text: str
    page_metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class DocumentMetadata:
    document_date: Optional[str] = None
    document_type: DocumentType = DocumentType.OUTROS
    creation_date: Optional[str] = None
    author: Optional[str] = None
    service: Optional[str] = None

@dataclass
class TextContent:
    text: str
    page_count: int
    extraction_method: str
    quality_level: QualityLevel
    char_count: int
    word_count: int
    metadata: Dict[str, Any] = field(default_factory=dict)
    pages_info: List[PageInfo] = field(default_factory=list)
    document_metadata: DocumentMetadata = field(default_factory=DocumentMetadata)

@dataclass
class ViolenceDetection:
    term: str
    category: str
    base_weight: float
    adjusted_weight: float
    context_phrase: str
    position_start: int
    position_end: int
    confidence_score: float = 1.0
    intensity_multiplier: float = 1.0
    found_date: Optional[str] = None
    full_sentence: str = ""
    page_number: int = 0
    document_date: Optional[str] = None

@dataclass
class ViolencePatterns:
    chronic_violence: bool = False
    escalation_pattern: bool = False
    weapons_involved: bool = False
    children_present: bool = False
    pregnancy_violence: bool = False
    sexual_violence: bool = False
    death_threats: bool = False
    multiple_injuries: bool = False
    psychological_control: bool = False
    economic_abuse: bool = False
    pattern_severity_score: float = 0.0

@dataclass
class AnalysisResult:
    patient_id: PatientIdentifier
    text_content: TextContent
    total_score: float
    base_score: float
    contextual_bonus: float
    severity_level: str
    detections: List[ViolenceDetection]
    violence_patterns: ViolencePatterns
    category_scores: Dict[str, float]
    category_counts: Dict[str, int]
    context_phrases: List[str]
    processing_time_ms: int
    status: ProcessingStatus
    error_message: Optional[str] = None

# BASE LEXICAL EXPANDIDA

class ExpandedViolenceLexicon:
    """Base lexical expandida com 1500+ termos para detec√ß√£o de viol√™ncia m√©dica"""

    def __init__(self):
        self.categories = self._load_expanded_violence_lexicon()
        self.compiled_patterns = {}
        self.negation_patterns = self._compile_negation_patterns()
        self.contextual_patterns = self._compile_contextual_patterns()
        self._compile_all_patterns()

    def _load_expanded_violence_lexicon(self) -> Dict[str, Dict[str, Any]]:
        """Carrega base lexical expandida com categorias especializadas"""
        return {
            "medical_formal": {
                "weight": 2.8,
                "terms": [
                    "trauma contundente", "trauma por for√ßa contusa", "les√£o contundente",
                    "trauma cranioencef√°lico", "TCE", "traumatismo craniano", "trauma facial",
                    "trauma cervical", "trauma tor√°cico", "trauma abdominal", "politraumatismo",
                    "hematoma subdural", "hematoma epidural", "hematoma intracraniano",
                    "hematoma retroauricular", "hematoma periorbit√°rio", "hematoma occipital",
                    "equimose periorbital", "hematoma periorbital", "olho roxo", "olho negro",
                    "equimoses m√∫ltiplas", "equimoses em diferentes est√°gios", "equimoses bilaterais",
                    "lacera√ß√£o cut√¢nea", "lacera√ß√£o facial", "lacera√ß√£o profunda",
                    "lacera√ß√£o do couro cabeludo", "lacera√ß√£o labial", "lacera√ß√£o genital",
                    "ferimento corto-contuso", "ferimento inciso", "ferimento perfurante",
                    "ferimento por arma de fogo", "ferimento por arma branca", "les√£o por proj√©til",
                    "fratura de mand√≠bula", "fratura maxilar", "fratura facial", "fratura nasal",
                    "fratura de √≥rbita", "fratura zigom√°tica", "fratura do arco zigom√°tico",
                    "fratura de costela", "fraturas m√∫ltiplas", "fratura espiral",
                    "queimadura intencional", "queimadura por cigarro", "queimadura circunscrita",
                    "queimadura por l√≠quido quente", "queimadura por ferro", "queimadura em luva",
                    "escoria√ß√µes m√∫ltiplas", "escoria√ß√µes lineares", "escoria√ß√µes ungueais",
                    "marcas de mordida humana", "marcas de dedos", "marcas de m√£o",
                    "marcas de corda", "marcas de estrangulamento", "marcas de amarra√ß√£o",
                    "pet√©quias no pesco√ßo", "equimoses cervicais", "sulco de enforcamento",
                    "les√µes de defesa", "ferimentos defensivos", "trauma n√£o acidental",
                    "viol√™ncia sexual", "estupro", "abuso sexual", "trauma genital",
                    "lacera√ß√£o vaginal", "lacera√ß√£o anal", "les√£o himenal", "hematoma genital",
                    "neglig√™ncia grave", "desnutri√ß√£o proteico-cal√≥rica", "abandono de incapaz",
                    "desidrata√ß√£o severa", "m√° higiene corporal", "les√µes por dec√∫bito",
                    "transtorno de estresse p√≥s-traum√°tico", "TEPT", "depress√£o reativa",
                    "ansiedade p√≥s-traum√°tica", "dissocia√ß√£o", "flashbacks",
                    "idea√ß√£o suicida", "tentativa de suic√≠dio", "automutila√ß√£o", "autoexterm√≠nio",
                    "comportamento autodestrutivo", "tentativa de autoles√£o",
                    "s√≠ndrome do beb√™ sacudido", "trauma craniano n√£o acidental",
                    "hemorragia retiniana", "hematoma subdural em crian√ßa"
                ]
            },
            "legal_police": {
                "weight": 2.5,
                "terms": [
                    "agress√£o f√≠sica", "agress√£o corporal", "viol√™ncia f√≠sica",
                    "les√£o corporal", "les√£o corporal leve", "les√£o corporal grave",
                    "les√£o corporal grav√≠ssima", "vias de fato", "viol√™ncia dom√©stica",
                    "amea√ßa", "amea√ßa de morte", "intimida√ß√£o", "amea√ßa grave",
                    "amea√ßa com arma", "amea√ßa de espancamento", "intimida√ß√£o psicol√≥gica",
                    "chantagem", "extors√£o", "coa√ß√£o", "constrangimento ilegal",
                    "c√°rcere privado", "sequestro", "sequestro rel√¢mpago",
                    "priva√ß√£o de liberdade", "confinamento for√ßado", "aprisionamento",
                    "estupro", "estupro de vulner√°vel", "atentado violento ao pudor",
                    "ass√©dio sexual", "abuso sexual", "explora√ß√£o sexual",
                    "viol√™ncia sexual", "estupro conjugal", "sexo for√ßado",
                    "homic√≠dio", "tentativa de homic√≠dio", "feminic√≠dio",
                    "tentativa de feminic√≠dio", "latroc√≠nio", "assassinato",
                    "arma branca", "arma de fogo", "objeto contundente",
                    "faca", "rev√≥lver", "pistola", "martelo",
                    "bast√£o", "cassetete", "pedra", "tijolo",
                    "espancamento", "surra", "paulada", "facada", "tiro",
                    "enforcamento", "estrangulamento", "sufocamento", "asfixia",
                    "boletim de ocorr√™ncia", "B.O.", "inqu√©rito policial",
                    "termo circunstanciado", "flagrante delito", "pris√£o em flagrante",
                    "medida protetiva de urg√™ncia", "ordem de prote√ß√£o",
                    "exame de corpo de delito", "laudo pericial", "per√≠cia criminal"
                ]
            },
            "maria_penha_domestic": {
                "weight": 2.3,
                "terms": [
                    "viol√™ncia dom√©stica", "viol√™ncia intrafamiliar", "viol√™ncia conjugal",
                    "viol√™ncia de g√™nero", "viol√™ncia contra mulher", "maus-tratos dom√©sticos",
                    "viol√™ncia no lar", "agress√£o dom√©stica", "abuso dom√©stico",
                    "feminic√≠dio", "tentativa de feminic√≠dio", "crime passional",
                    "ciclo da viol√™ncia", "ciclo de abuso", "escalada da viol√™ncia",
                    "viol√™ncia repetitiva", "padr√£o de agress√£o", "hist√≥rico de viol√™ncia",
                    "relacionamento abusivo", "namoro violento", "parceiro abusivo",
                    "companheiro violento", "marido agressor", "ex-parceiro violento",
                    "viol√™ncia f√≠sica dom√©stica", "viol√™ncia psicol√≥gica", "viol√™ncia moral",
                    "viol√™ncia sexual conjugal", "viol√™ncia patrimonial", "viol√™ncia econ√¥mica",
                    "controle coercitivo", "domina√ß√£o psicol√≥gica", "ci√∫mes patol√≥gicos",
                    "possessividade excessiva", "controle obsessivo", "comportamento controlador",
                    "isolamento social for√ßado", "proibi√ß√£o de trabalhar", "proibi√ß√£o de sair",
                    "proibi√ß√£o de estudar", "afastamento da fam√≠lia", "isolamento de amigos",
                    "monitoramento digital", "controle de celular", "cyberstalking",
                    "viol√™ncia virtual", "stalking digital", "persegui√ß√£o online",
                    "humilha√ß√£o constante", "gaslighting", "chantagem emocional",
                    "manipula√ß√£o psicol√≥gica", "terrorismo psicol√≥gico", "tortura psicol√≥gica",
                    "destrui√ß√£o de objetos pessoais", "controle financeiro absoluto",
                    "priva√ß√£o de recursos", "destrui√ß√£o de documentos", "delegacia da mulher",
                    "casa abrigo", "medidas protetivas", "centro de refer√™ncia"
                ]
            },
            "healthcare_nursing": {
                "weight": 2.0,
                "terms": [
                    "paciente relata viol√™ncia", "usu√°rio informa agress√£o", "refere maus-tratos",
                    "hist√≥ria de viol√™ncia", "epis√≥dios de viol√™ncia", "relato de agress√£o",
                    "menciona espancamento", "conta sobre agress√£o", "narra viol√™ncia",
                    "hist√≥ria pregressa de viol√™ncia", "epis√≥dios anteriores de viol√™ncia",
                    "antecedentes de maus-tratos", "hist√≥rico de agress√µes",
                    "viol√™ncia recorrente", "agress√µes repetidas", "maus-tratos cr√¥nicos",
                    "sinais evidentes de viol√™ncia", "ind√≠cios de maus-tratos",
                    "suspeita de viol√™ncia dom√©stica", "les√µes compat√≠veis com agress√£o",
                    "ferimentos sugestivos", "padr√£o de les√µes", "les√µes n√£o acidentais",
                    "hematomas m√∫ltiplos", "equimoses generalizadas", "roxos pelo corpo",
                    "marcas vis√≠veis", "ferimentos em cicatriza√ß√£o", "les√µes recentes",
                    "queimaduras circunscritas", "marca de cigarro", "queimadura suspeita",
                    "escoria√ß√µes lineares", "arranh√µes defensivos", "marcas de unhas",
                    "din√¢mica familiar conturbada", "relacionamento conjugal conflituoso",
                    "ambiente familiar violento", "tens√£o familiar evidente",
                    "filhos presenciam viol√™ncia", "crian√ßas traumatizadas",
                    "menores expostos √† viol√™ncia", "impacto psicol√≥gico nas crian√ßas",
                    "comportamento de submiss√£o", "evita contato visual", "hipervigil√¢ncia",
                    "medo excessivo", "ansiedade extrema", "comportamento evasivo",
                    "tremores generalizados", "sudorese profusa", "taquicardia",
                    "notifica√ß√£o compuls√≥ria", "ficha de notifica√ß√£o de viol√™ncia",
                    "comunica√ß√£o ao conselho tutelar", "relat√≥rio de suspeita"
                ]
            },
            "colloquial_popular": {
                "weight": 1.8,
                "terms": [
                    "surra", "porrada", "pancada", "sova", "cacetada", "paulada",
                    "bordoada", "tap√£o", "sopapo", "bicuda", "coice", "pesco√ß√£o",
                    "soco", "murro", "tapa", "bofetada", "cascudo", "chute", "pontap√©",
                    "joelhada", "cabe√ßada", "cotovelada", "pis√£o", "empurr√£o", "belisc√£o",
                    "bateu na mulher", "agrediu a esposa", "espancou a companheira",
                    "deu uma surra", "quebrou na porrada", "meteu a m√£o",
                    "me bateu", "apanhei dele", "levei surra", "me deu porrada",
                    "me agrediu", "me espancou", "bateu em mim", "me machucou",
                    "amea√ßou me matar", "disse que me mata", "prometeu me acabar",
                    "falou que ia me quebrar", "amea√ßou me dar uma surra",
                    "muito ciumento", "n√£o deixa sair", "controla tudo", "mexe no celular",
                    "n√£o deixa trabalhar", "vigia sempre", "segue para todo lado",
                    "me for√ßou", "me obrigou", "n√£o aceitou n√£o", "for√ßou a barra",
                    "briga de casal", "confus√£o em casa", "quebra-pau em casa",
                    "barraco em casa", "discuss√£o feia", "briga violenta",
                    "bebe e fica violento", "viciado agressivo", "noiado violento",
                    "tacou objeto", "jogou coisa", "atirou na parede",
                    "ficou todo roxo", "marcou o rosto", "deixou marca"
                ]
            },
            "orthographic_variations": {
                "weight": 1.5,
                "terms": [
                    "agress√£o", "agre√ß√£o", "agressao", "agres√£o", "agrediu", "agridiu",
                    "agredindo", "agridindo", "agressor", "agresor", "agressivo", "agresivo",
                    "viol√™ncia", "violencia", "violensia", "violensa", "violento", "viol√™nto",
                    "espancamento", "spancamento", "espancou", "espankou", "espancada",
                    "machucou", "machukou", "machucu", "machucado", "machucada",
                    "bateu", "bat√™u", "batu", "batendo", "bateno", "bater", "bat√™",
                    "amea√ßou", "amea√ß√¥", "amea√ßo", "amea√ßando", "amea√ßano", "amea√ßa", "ameasa",
                    "judiou", "judi√¥", "judiar", "judi√°", "maltratou", "maltrat√≥"
                ]
            },
            "psychological_abuse": {
                "weight": 1.9,
                "terms": [
                    "manipula√ß√£o psicol√≥gica", "chantagem emocional", "gaslighting",
                    "lavagem cerebral", "distor√ß√£o da realidade", "confus√£o mental induzida",
                    "humilha√ß√£o constante", "desmoraliza√ß√£o", "diminui√ß√£o sistem√°tica",
                    "isolamento social", "afastamento for√ßado", "separa√ß√£o de familiares",
                    "controle mental", "domina√ß√£o psicol√≥gica", "subjuga√ß√£o emocional"
                ]
            },
            "child_specific": {
                "weight": 2.7,
                "terms": [
                    "maus-tratos infantis", "abuso infantil", "neglig√™ncia infantil",
                    "viol√™ncia contra crian√ßa", "agress√£o a menor", "maltrato infantil",
                    "s√≠ndrome do beb√™ sacudido", "trauma craniano n√£o acidental em crian√ßa",
                    "les√µes n√£o acidentais em menor", "neglig√™ncia de cuidados b√°sicos",
                    "priva√ß√£o de alimentos", "falta de higiene", "abandono de incapaz"
                ]
            }
        }

    def _compile_negation_patterns(self) -> List[re.Pattern]:
        """Compila padr√µes de nega√ß√£o expandidos"""
        negation_terms = [
            "n√£o", "nao", "jamais", "nunca", "nega", "negou", "descarta",
            "afasta", "exclui", "ausente", "sem", "inexistente", "improv√°vel",
            "sem evid√™ncias", "sem ind√≠cios", "sem sinais", "descartado"
        ]

        patterns = []
        for term in negation_terms:
            pattern = re.compile(
                rf'\b{re.escape(term)}\b[\s\w]{{0,80}}\b(?:viol|agred|espanc|machuc|bat|surr|amea√ß|mal.?trat)\w*',
                re.IGNORECASE
            )
            patterns.append(pattern)

        return patterns

    def _compile_contextual_patterns(self) -> Dict[str, List[re.Pattern]]:
        """Compila padr√µes contextuais expandidos"""
        return {
            "intensifying_contexts": [
                re.compile(r'\b(sempre|todo\s*dia|constantemente|frequentemente|diariamente|rotineiramente)\b.{0,50}\b(agred|bat|violent|maltrat)\w*', re.IGNORECASE),
                re.compile(r'\b(na\s*frente|presen√ßa|vista)\b.{0,30}\b(crian√ßas?|filhos?|menores?)\b.{0,50}\b(agred|bat|violent)\w*', re.IGNORECASE),
                re.compile(r'\b(gr√°vida|gestante|gesta√ß√£o)\b.{0,50}\b(agred|bat|chut|violent|espanc)\w*', re.IGNORECASE),
                re.compile(r'\b(com|usando|amea√ßou\s*com|empunhando)\b.{0,30}\b(faca|rev√≥lver|pistola|arma|martelo)\b', re.IGNORECASE),
            ],
            "medical_severity": [
                re.compile(r'\b(fratura|sangramento|hemorragia|trauma)\b.{0,30}\b(agred|bat|violent)\w*', re.IGNORECASE),
                re.compile(r'\b(cirurgia|sutura|pontos)\b.{0,50}\b(agred|bat|violent)\w*', re.IGNORECASE),
            ]
        }

    def _compile_all_patterns(self):
        """Compila todos os padr√µes regex"""
        for category, data in self.categories.items():
            terms_escaped = [re.escape(term) for term in data['terms']]
            combined_pattern = '|'.join(terms_escaped)
            full_pattern = rf'(.{{0,150}})({combined_pattern})(.{{0,150}})'

            self.compiled_patterns[category] = {
                'pattern': re.compile(full_pattern, re.IGNORECASE | re.DOTALL),
                'weight': data['weight'],
                'terms_count': len(data['terms'])
            }

    def detect_negation_context(self, text: str, match_start: int, match_end: int) -> bool:
        """Detecta contexto de nega√ß√£o"""
        context_start = max(0, match_start - 150)
        before_context = text[context_start:match_end]

        for negation_pattern in self.negation_patterns:
            if negation_pattern.search(before_context):
                return True
        return False

    def analyze_contextual_intensity(self, text: str, detection: ViolenceDetection) -> float:
        """Analisa intensidade contextual expandida"""
        intensity_multiplier = 1.0

        start = max(0, detection.position_start - 200)
        end = min(len(text), detection.position_end + 200)
        context = text[start:end].lower()

        # Verificar contextos intensificadores
        for pattern in self.contextual_patterns['intensifying_contexts']:
            if pattern.search(context):
                intensity_multiplier += 0.5

        # Verificar severidade m√©dica
        for pattern in self.contextual_patterns['medical_severity']:
            if pattern.search(context):
                intensity_multiplier += 0.7

        return max(0.1, min(5.0, intensity_multiplier))

    def detect_violence_patterns(self, text: str) -> ViolencePatterns:
        """Detecta padr√µes espec√≠ficos de viol√™ncia expandidos"""
        text_lower = text.lower()
        patterns = ViolencePatterns()

        # Viol√™ncia cr√¥nica
        chronic_indicators = ['sempre', 'todo dia', 'constantemente', 'anos', 'rotina', 'frequentemente']
        if any(indicator in text_lower for indicator in chronic_indicators):
            patterns.chronic_violence = True
            patterns.pattern_severity_score += 1.2

        # Armas
        weapons = ['faca', 'revolver', 'pistola', 'arma', 'martelo']
        if any(weapon in text_lower for weapon in weapons):
            patterns.weapons_involved = True
            patterns.pattern_severity_score += 1.8

        # Crian√ßas presentes
        children_contexts = ['na frente das crian√ßas', 'crian√ßa viu', 'filho assistiu']
        if any(context in text_lower for context in children_contexts):
            patterns.children_present = True
            patterns.pattern_severity_score += 1.5

        # Viol√™ncia na gravidez
        pregnancy_terms = ['gr√°vida', 'gestante', 'chutou barriga']
        if any(term in text_lower for term in pregnancy_terms):
            patterns.pregnancy_violence = True
            patterns.pattern_severity_score += 2.2

        # Viol√™ncia sexual
        sexual_terms = ['estupro', 'abuso sexual', 'for√ßou', 'obrigou']
        if any(term in text_lower for term in sexual_terms):
            patterns.sexual_violence = True
            patterns.pattern_severity_score += 2.5

        # Amea√ßas de morte
        death_threats = ['vou te matar', 'vai morrer', 'amea√ßou de morte']
        if any(threat in text_lower for threat in death_threats):
            patterns.death_threats = True
            patterns.pattern_severity_score += 2.0

        return patterns

# EXTRATOR DE TEXTO

class EnhancedTextExtractor:
    """Extrator de texto incrementado com informa√ß√µes de p√°gina e metadados"""

    def __init__(self, config: ProcessingConfig):
        self.config = config
        self.logger = logging.getLogger("EnhancedTextExtractor")
        self.document_classifier = DocumentClassifier()
        self.metadata_extractor = DocumentMetadataExtractor()

    def extract_from_pdf(self, pdf_path: Path) -> TextContent:
        """Extrai texto com informa√ß√µes de p√°gina e metadados"""

        # Validar arquivo
        self._validate_input_file(pdf_path)

        # Tentar m√©todos em ordem de prefer√™ncia
        extraction_methods = []

        if HAS_PDFPLUMBER:
            extraction_methods.append(("pdfplumber", self._extract_with_pdfplumber))
        if HAS_FITZ:
            extraction_methods.append(("fitz", self._extract_with_fitz))
        if HAS_OCR:
            extraction_methods.append(("ocr", self._extract_with_ocr))

        if not extraction_methods:
            raise Exception("Nenhuma biblioteca de PDF dispon√≠vel")

        last_error = None

        for method_name, extract_method in extraction_methods:
            try:
                print(f"  Tentando {method_name}...")
                text, metadata, pages_info = extract_method(pdf_path)

                if self._is_sufficient_text(text):
                    quality = self._assess_text_quality(text)
                    print(f"  ‚úì Sucesso com {method_name}")

                    # Extrair metadados do documento
                    doc_metadata = self.metadata_extractor.extract_metadata(text, pages_info)

                    return TextContent(
                        text=self._clean_text(text),
                        page_count=metadata.get('page_count', 0),
                        extraction_method=method_name,
                        quality_level=quality,
                        char_count=len(text),
                        word_count=len(text.split()),
                        metadata=metadata,
                        pages_info=pages_info,
                        document_metadata=doc_metadata
                    )
                else:
                    print(f"  ‚ö† Texto insuficiente com {method_name}")
            except Exception as e:
                last_error = e
                print(f"  ‚úó {method_name} falhou: {e}")
                continue

        raise Exception(f"Todos os m√©todos falharam para {pdf_path.name}. √öltimo erro: {last_error}")

    def _validate_input_file(self, file_path: Path):
        """Valida arquivo de entrada"""
        if not file_path.exists():
            raise FileNotFoundError(f"Arquivo n√£o encontrado: {file_path}")

        file_size_mb = file_path.stat().st_size / (1024 * 1024)
        if file_size_mb > self.config.max_file_size_mb:
            raise Exception(f"Arquivo muito grande: {file_size_mb:.2f}MB")

        if file_path.suffix.lower() != '.pdf':
            raise Exception(f"Tipo de arquivo n√£o suportado: {file_path.suffix}")

    def _extract_with_pdfplumber(self, pdf_path: Path) -> Tuple[str, Dict, List[PageInfo]]:
        """Extra√ß√£o com pdfplumber - INCREMENTADA"""
        text = ""
        metadata = {"method": "pdfplumber", "pages_processed": []}
        pages_info = []

        with pdfplumber.open(pdf_path) as pdf:
            metadata['page_count'] = len(pdf.pages)

            for i, page in enumerate(pdf.pages):
                try:
                    page_text = page.extract_text()
                    if page_text and len(page_text.strip()) > 10:
                        text += f"\n--- P√ÅGINA {i+1} ---\n{page_text}\n"
                        metadata['pages_processed'].append(i+1)

                        # Criar informa√ß√µes da p√°gina
                        page_info = PageInfo(
                            page_number=i+1,
                            page_text=page_text,
                            page_metadata={
                                'width': page.width,
                                'height': page.height,
                                'rotation': getattr(page, 'rotation', 0)
                            }
                        )
                        pages_info.append(page_info)
                except Exception:
                    continue

        return text, metadata, pages_info

    def _extract_with_fitz(self, pdf_path: Path) -> Tuple[str, Dict, List[PageInfo]]:
        """Extra√ß√£o com PyMuPDF - INCREMENTADA"""
        text = ""
        metadata = {"method": "fitz", "pages_processed": []}
        pages_info = []

        doc = fitz.open(pdf_path)
        metadata['page_count'] = len(doc)

        for page_num in range(len(doc)):
            try:
                page = doc.load_page(page_num)
                page_text = page.get_text()
                if page_text and len(page_text.strip()) > 10:
                    text += f"\n--- P√ÅGINA {page_num+1} ---\n{page_text}\n"
                    metadata['pages_processed'].append(page_num+1)

                    # Criar informa√ß√µes da p√°gina
                    page_info = PageInfo(
                        page_number=page_num+1,
                        page_text=page_text,
                        page_metadata={
                            'rect': page.rect,
                            'rotation': page.rotation
                        }
                    )
                    pages_info.append(page_info)
            except Exception:
                continue

        doc.close()
        return text, metadata, pages_info

    def _extract_with_ocr(self, pdf_path: Path) -> Tuple[str, Dict, List[PageInfo]]:
        """Extra√ß√£o com OCR - INCREMENTADA"""
        text = ""
        metadata = {"method": "ocr", "pages_processed": []}
        pages_info = []

        try:
            pages = convert_from_path(pdf_path, dpi=300, first_page=1, last_page=5)
            metadata['page_count'] = len(pages)

            for i, page_image in enumerate(pages):
                try:
                    page_text = pytesseract.image_to_string(page_image, lang='por')

                    if page_text and len(page_text.strip()) > 20:
                        text += f"\n--- P√ÅGINA {i+1} (OCR) ---\n{page_text}\n"
                        metadata['pages_processed'].append(i+1)

                        # Criar informa√ß√µes da p√°gina
                        page_info = PageInfo(
                            page_number=i+1,
                            page_text=page_text,
                            page_metadata={
                                'ocr_method': 'pytesseract',
                                'image_size': page_image.size
                            }
                        )
                        pages_info.append(page_info)
                except Exception:
                    continue
        except Exception as e:
            raise Exception(f"Erro OCR: {e}")

        return text, metadata, pages_info

    def _is_sufficient_text(self, text: str) -> bool:
        """Verifica se o texto √© suficiente"""
        if not text:
            return False
       
